{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JsdhCm7yB71r","colab_type":"text"},"source":["#  回帰\n","回帰は、教師あり学習の一種で、変数間の関係を予測します。  \n","今回は、単回帰と重回帰の２つを解説します。"]},{"cell_type":"markdown","metadata":{"id":"Tgby3w-wB_6w","colab_type":"text"},"source":["## ●データセットの読み込み\n","ボストン住宅価格のデータセットを読み込みます。  \n","このデータセットには、**説明変数**と**目的変数**が含まれます。  \n","**説明変数**: 何かの原因となっている変数  \n","**目的変数**: その原因を受けて発生した結果である変数"]},{"cell_type":"code","metadata":{"id":"tlCabWPRDYLd","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn import datasets\n","\n","boston = datasets.load_boston()\n","boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)  # data: 説明変数\n","boston_df[\"PRICE\"] = boston.target  # target: 目的変数\n","boston_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eg-bGiq0liRo","colab_type":"text"},"source":["説明変数が様々な住宅の特徴で、目的変数が住宅の価格であることが分かります。  \n","各列のラベルの意味は、`DESCR`により表示することができます。"]},{"cell_type":"code","metadata":{"id":"5_Qgk5prfZno","colab_type":"code","colab":{}},"source":["print(boston.DESCR)  # データセットの説明"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hrhhxgg3mdF3","colab_type":"text"},"source":["データセットの特徴を把握するために、統計量を表示します。"]},{"cell_type":"code","metadata":{"id":"IGl9eXt-RVnu","colab_type":"code","colab":{}},"source":["boston_df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5NrEwdREmpOQ","colab_type":"text"},"source":["データセットを、訓練用のデータとテスト用のデータに分割します。"]},{"cell_type":"code","metadata":{"id":"8gr3rX3uYxGr","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","# 訓練データとテストデータに分割\n","x_train, x_test, t_train, t_test = train_test_split(boston.data, boston.target, random_state=0) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4P87IMlUQtsN","colab_type":"text"},"source":["## ●単回帰\n","単回帰では、直線を使い1つの説明変数で目的変数を予測します。  \n","$x$を説明変数、$y$を目的変数、$a$を係数、$b$を切片としたとき、単回帰は以下の式で表されます。  \n","$$y = ax + b$$"]},{"cell_type":"code","metadata":{"id":"AgnQ5FJCQstZ","colab_type":"code","colab":{}},"source":["from sklearn import linear_model\n","\n","# RM（部屋数）の列を取得\n","x_rm_train = x_train[:, [5]]\n","x_rm_test = x_test[:, [5]]\n","\n","model = linear_model.LinearRegression() # 線形回帰モデル\n","model.fit(x_rm_train, t_train)  # モデルの訓練"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBgb0ZLJt7rz","colab_type":"text"},"source":["係数と切片を取得します。"]},{"cell_type":"code","metadata":{"id":"yRNtXC_mTDy6","colab_type":"code","colab":{}},"source":["a = model.coef_ # 係数\n","b = model.intercept_ # 切片\n","print(\"a: \", a) \n","print(\"b: \", b) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgtKKpm3xMqG","colab_type":"text"},"source":["データ及び回帰直線をグラフで表示します。"]},{"cell_type":"code","metadata":{"id":"9Pj4AMghTEqb","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","plt.scatter(x_rm_train, t_train, label=\"Train\")\n","plt.scatter(x_rm_test, t_test, label=\"Test\")\n","\n","y_reg = a * x_rm_train + b  # 回帰直線\n","plt.plot(x_rm_train, y_reg, c=\"red\") \n","\n","plt.xlabel(\"Rooms\")\n","plt.ylabel(\"Price\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfmsL445zs7a","colab_type":"text"},"source":["モデルをMSE（平均二乗誤差 Mean Squared Error）を計算します。  \n","\n","MSEは、$E$を誤差、$y_k$を予測値、$t_k$を正解値として以下の式で定義されます。\n","\n","$$ E = \\frac{1}{n} \\sum_{k=1}^n(y_k-t_k)^2 $$\n","\n","この誤差が小さいほどモデルの誤差が小さくなります。  \n","\n","以下のコードは、訓練データとテストデータ、それぞれでMSEを計算します。"]},{"cell_type":"code","metadata":{"id":"lEyltLb0TNYW","colab_type":"code","colab":{}},"source":["from sklearn.metrics import mean_squared_error\n","\n","# 訓練データ\n","y_train = model.predict(x_rm_train)\n","mse_train = mean_squared_error(t_train, y_train)\n","print(\"MSE(Train): \", mse_train)\n","\n","# テストデータ\n","y_test = model.predict(x_rm_test)\n","mse_test = mean_squared_error(t_test, y_test)\n","print(\"MSE(Test): \", mse_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dScbFa4HU5Zj","colab_type":"text"},"source":["## ●重回帰\n","重回帰では、複数の説明変数を使い目的変数を予測します。  \n","重回帰は、$x_k$を各説明変数として以下の式で表されます。\n","\n","$$ y = \\sum_{k=1}^na_kx_k + b $$\n","\n","今回は、13種類の説明変数を全て使って重回帰分析を行います。"]},{"cell_type":"code","metadata":{"id":"O2Sr3TJuU4jT","colab_type":"code","colab":{}},"source":["model = linear_model.LinearRegression() # 線形回帰\n","\n","# 全ての説明変数を使い学習\n","model.fit(x_train, t_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HItdTbCX7Nsd","colab_type":"text"},"source":["各説明変数に対応した係数を取得します。"]},{"cell_type":"code","metadata":{"id":"rg1l1t7mV8ma","colab_type":"code","colab":{}},"source":["a_df = pd.DataFrame(boston.feature_names, columns=[\"Exp\"])\n","a_df[\"a\"] = pd.Series(model.coef_)\n","a_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27-HM_yb8ekG","colab_type":"text"},"source":["切片を取得します。"]},{"cell_type":"code","metadata":{"id":"hl9WSsgwWMFD","colab_type":"code","colab":{}},"source":["print(\"b: \", model.intercept_)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ANkxMZz8tpr","colab_type":"text"},"source":["訓練データとテストデータ、それぞれでMSE（平均二乗誤差）を計算します。"]},{"cell_type":"code","metadata":{"id":"hSAEnKfTWPn1","colab_type":"code","colab":{}},"source":["# 訓練データ\n","y_train = model.predict(x_train)\n","mse_train = mean_squared_error(t_train, y_train)\n","print(\"MSE(Train): \", mse_train)\n","\n","# テストデータ\n","y_test = model.predict(x_test)\n","mse_test = mean_squared_error(t_test, y_test)\n","print(\"MSE(Test): \", mse_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PSDZ-RKt9g2D","colab_type":"text"},"source":["単回帰の場合よりも誤差が小さくなりました。  \n","ただ、テストデータの誤差は訓練データの誤差よりも大幅に大きくなりました。  \n","モデルが訓練データに過剰に適合していないか、慎重に判断する必要があります。"]}]}